{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d640047c",
   "metadata": {},
   "source": [
    "# Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4f50ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae5a18ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "from google.oauth2 import service_account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b8a4ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_to_folder():\n",
    "    BUCKET_NAME = \"mvp_youtube_optimizer\"\n",
    "    storage_dir = \"lunch3\"\n",
    "    local_dir = \"bucket_data_2/\" #Create this manually\n",
    "\n",
    "    my_credentials = service_account.Credentials.from_service_account_file(\"massive-pen-365111-8eaed18fb748.json\")\n",
    "\n",
    "    client = storage.Client(credentials=my_credentials)\n",
    "    bucket = client.bucket(BUCKET_NAME)\n",
    "    blob = bucket.blob(storage_dir)\n",
    "    \n",
    "    blobs = bucket.list_blobs(prefix =storage_dir)\n",
    "    for blob in blobs:\n",
    "        filename = blob.name.replace('/','_')\n",
    "        blob.download_to_filename(local_dir + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "649c58ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder='/Users/nicolafriedrich/code/jacksharples1/youtube_optimizer/bucket_data_2'):\n",
    "    images = []\n",
    "    views = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if len(filename)< len('lunch3')+1:\n",
    "            continue\n",
    "\n",
    "        else:\n",
    "            img = plt.imread(os.path.join(folder,filename))\n",
    "            if img.shape != (180,320,3):\n",
    "                print(img.shape)\n",
    "                continue\n",
    "            else:\n",
    "                last_underscore = filename.rfind('_')\n",
    "                y = int(filename[last_underscore +1:])\n",
    "                images.append(list(img))\n",
    "                views.append(y)\n",
    "    return images, views\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69a3e4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloading():\n",
    "    get_images_to_folder()\n",
    "    X,y = load_images_from_folder()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a63ba3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 120, 3)\n",
      "(90, 120, 3)\n",
      "(90, 120, 3)\n",
      "(90, 120, 3)\n",
      "(90, 120, 3)\n",
      "(90, 120, 3)\n",
      "(90, 120, 3)\n",
      "(90, 120, 3)\n",
      "(90, 120, 3)\n",
      "(90, 120, 3)\n",
      "(90, 120, 3)\n",
      "(90, 120, 3)\n",
      "(90, 120, 3)\n",
      "(90, 120, 3)\n",
      "(90, 120, 3)\n",
      "(90, 120, 3)\n",
      "(90, 120, 3)\n",
      "(90, 120, 3)\n",
      "(90, 120, 3)\n",
      "(90, 120, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = dataloading()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abbb1eb",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "809eef09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-29 17:11:50.867568: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.xception import Xception\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Flatten\n",
    "from keras.models import Sequential\n",
    "#from keras.optimizers import SGD\n",
    "#import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fa9e1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_model():\n",
    "    base_model = Xception(weights=\"imagenet\",input_shape = (180,320,3),include_top=False)\n",
    "    base_model.trainable = False\n",
    "    return base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dedbeeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_model():\n",
    "    model = Sequential((\n",
    "        base_model(),\n",
    "        GlobalAveragePooling2D(),\n",
    "        Flatten(),\n",
    "        Dense(100,activation = 'relu'),\n",
    "        Dense(50,activation = 'relu'),\n",
    "        Dense(1,activation = 'linear')))\n",
    "    \n",
    "    model.compile(loss=\"mse\", optimizer='adam',\n",
    "                  metrics=[\"mae\"])\n",
    "    \n",
    "    return model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98d547f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-29 17:12:01.055741: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " xception (Functional)       (None, 6, 10, 2048)       20861480  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               204900    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,071,481\n",
      "Trainable params: 210,001\n",
      "Non-trainable params: 20,861,480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = complete_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02822422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4334, 180, 320, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a56a2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(patience = 15, restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bc0da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "193/217 [=========================>....] - ETA: 1:16 - loss: 161446696583168.0000 - mae: 2831453.5000"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train, epochs = 1000,batch_size = 16,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a46b61",
   "metadata": {},
   "source": [
    "# Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc02540",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8e850a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.abs(y_train - np.mean(y_train)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
