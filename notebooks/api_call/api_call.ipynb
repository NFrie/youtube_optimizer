{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from words import words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = words.splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "TESTING = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from google.cloud import storage\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "from random import randrange\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TESTING:\n",
    "    keys = os.environ.get('API_TEST_KEY')\n",
    "else:\n",
    "    keys = os.environ.get('API_KEYS')\n",
    "keys = keys.split('@')\n",
    "bucket_name = os.environ.get('BUCKET_NAME')\n",
    "bucket_name = 'mvp_youtube_optimizer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AIzaSyAd8pFaz0Ase2FAVOnswa98SHrxqD7XWv0',\n",
       " 'AIzaSyC7XiyFhSSwTD5WSs1x6rx09kS2jFSQTDY',\n",
       " 'AIzaSyD9qZNqlkwOIbHLa5F3DOzjaveD4gvB4XA',\n",
       " 'AIzaSyDyZ2K0uu5Q5zyWI2ZOQE48SfLB-2cp2wU',\n",
       " 'AIzaSyDeRN24pG45WvcE3WSKAwQx8Qpp__CUCt0',\n",
       " 'AIzaSyB2A6hF1oR0mjhJEvAmRvIqsyV_uD1VK5s',\n",
       " 'AIzaSyBejskpHPUJXfX2vmY9ba8DMd2FOyuBnis',\n",
       " 'AIzaSyDAerNtsJh0-Ar6xGbchqrYu3E9zFkkAaY',\n",
       " 'AIzaSyD7QuMDoalNZ_YfVHu4KYOcCb6pm1RwqVo',\n",
       " 'AIzaSyDPEfVUYh5tKBUWbYWfCac1JD5haoCXNHo',\n",
       " 'AIzaSyBghueDNP7l392IcesMBNOdBES7J9RVd1U',\n",
       " 'AIzaSyA5QTExvUBGszQpBasZpKGwE6legAjIBYs',\n",
       " 'AIzaSyBWyRyxR0n6U5D8LGOLQZgwjZxVxj8MVHE',\n",
       " 'AIzaSyBddAe3mXSLmTsavOxpR_9Lhn3v_UOPpfE']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = datetime.datetime.strptime('5/5/2022 1:30 PM', '%d/%m/%Y %I:%M %p')\n",
    "ledge = time.replace(tzinfo=datetime.timezone.utc)\n",
    "ledge = ledge.isoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_blob(bucket_name, source_file_name, destination_blob_name):\n",
    "    \"\"\"Uploads a file to the bucket.\"\"\"\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(f'{bucket_name}')\n",
    "    blob = bucket.blob(f'{query_type}/{destination_blob_name}')\n",
    "\n",
    "    blob.upload_from_filename(source_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['id','channel_id','country', 'channel_viewCount','channel_subscriberCount','channel_videoCount','title','published','views']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_query(query,max_results,start,end,ledge,hours=0,number_of_words=0):\n",
    "    global df_to_add\n",
    "    global count\n",
    "    \n",
    "    \n",
    "    # Iterate over keys\n",
    "    for number, key in enumerate(keys):\n",
    "        # print(f\"Working on key number: {number + 1}\")\n",
    "        \n",
    "        # Generate a random date and date before\n",
    "        # date, date_before = random_date(start, end, hours)\n",
    "        \n",
    "        # print(date)\n",
    "        # print(date_before)\n",
    "        \n",
    "        # API call\n",
    "        search_url = \"https://youtube.googleapis.com/youtube/v3/search\"\n",
    "        \n",
    "        if query == None:\n",
    "            word_list = words[:number_of_words]\n",
    "            # search = random.choice(word_list)\n",
    "            search = word_list[count+200]\n",
    "            count = count + 1\n",
    "            print(search)\n",
    "        else:\n",
    "            search = query\n",
    "            \n",
    "        if hours:\n",
    "            params = {\n",
    "                'publishedBefore':end,\n",
    "                'publishedAfter':start,\n",
    "                'part':'snippet',\n",
    "                'order':'date',\n",
    "                'q':search,\n",
    "                'type':'video',\n",
    "                'key': key,\n",
    "                'maxResults': max_results\n",
    "                }\n",
    "        \n",
    "        else:\n",
    "            # print(end)\n",
    "            params = {\n",
    "                'publishedBefore':ledge,\n",
    "                'part':'snippet',\n",
    "                'order':'date',\n",
    "                'q':search,\n",
    "                'type':'video',\n",
    "                'key': key,\n",
    "                'maxResults': max_results}\n",
    "        \n",
    "        # API response\n",
    "        search_response = requests.get(url=search_url, params=params)\n",
    "        if search_response.status_code != 200:\n",
    "            print(search_response.status_code)\n",
    "            continue\n",
    "        \n",
    "        search_json = search_response.json()\n",
    "        # print(search_json)\n",
    "        \n",
    "        # If empty items -> no results -> break to the next key and date\n",
    "        \n",
    "        if not search_json['items']:\n",
    "                continue\n",
    "            \n",
    "        # Iterate over items in results\n",
    "        \n",
    "        for i in tqdm(range(len(search_json['items']))):\n",
    "            \n",
    "            # Add features\n",
    "            video_id = search_json['items'][i]['id']['videoId']\n",
    "            channel_id = search_json['items'][i]['snippet']['channelId']\n",
    "            title = search_json['items'][i]['snippet']['title']\n",
    "            published = search_json['items'][i]['snippet']['publishedAt']\n",
    "            image_url = search_json['items'][i]['snippet']['thumbnails']['medium']['url']\n",
    "\n",
    "                \n",
    "            # Video Statistics API call and response\n",
    "            video_stats_url = f\"https://youtube.googleapis.com/youtube/v3/videos?id={video_id}&part=statistics&key={key}\"\n",
    "            video_stats_response = requests.get(url=video_stats_url)\n",
    "            video_stats_json = video_stats_response.json()\n",
    " \n",
    "            # If no statistics skip this video\n",
    "            if not video_stats_json.get('items'):\n",
    "                continue\n",
    "            \n",
    "            # Add feature\n",
    "            view_count = video_stats_json['items'][0]['statistics'].get('viewCount')\n",
    "\n",
    "            \n",
    "            # Channel Statistics API call and response\n",
    "            channel_stats_url = f\"https://youtube.googleapis.com/youtube/v3/channels?part=snippet%2CcontentDetails%2Cstatistics&id={channel_id}&key={key}\"\n",
    "            channel_stats_response = requests.get(url=channel_stats_url)\n",
    "            channel_stats_json = channel_stats_response.json()\n",
    "            \n",
    "            \n",
    "            country = None\n",
    "            channel_viewCount = None\n",
    "            channel_subscriberCount =  None\n",
    "            channel_videoCount = None\n",
    "            \n",
    "            # Add features\n",
    "            if channel_stats_json.get('items'):\n",
    "                country = channel_stats_json['items'][0]['snippet'].get('country')\n",
    "                channel_viewCount = channel_stats_json['items'][0]['statistics']['viewCount']\n",
    "                channel_subscriberCount = channel_stats_json['items'][0]['statistics']['subscriberCount']\n",
    "                channel_videoCount = channel_stats_json['items'][0]['statistics']['videoCount']\n",
    "            \n",
    "            # Update dataframe with new row\n",
    "            new_row = pd.DataFrame([[video_id,\n",
    "                                     channel_id,\n",
    "                                     country,\n",
    "                                     channel_viewCount,\n",
    "                                     channel_subscriberCount,\n",
    "                                     channel_videoCount,\n",
    "                                     title,\n",
    "                                     published,\n",
    "                                     view_count]], columns=features)\n",
    "            \n",
    "            df_to_add = pd.concat([df_to_add,new_row],axis=0)\n",
    "            \n",
    "            \n",
    "            # Save image\n",
    "            img_data = requests.get(image_url).content\n",
    "            with open(f'temp.jpg', 'wb') as handler:\n",
    "                handler.write(img_data)\n",
    "                \n",
    "            # Upload image\n",
    "            upload_blob(bucket_name,'./temp.jpg',f'{video_id}_{view_count}')\n",
    "    \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = pd.DataFrame(columns = [\"name\",\"views\"])\n",
    "\n",
    "for image in range(0,len(img_file_buffer)):\n",
    "    for title in range(0,len(titles)):\n",
    "        #views[image][title] = requests.post(url).json() #image, title as params\n",
    "        #views[f'{image},{title}']=5\n",
    "        name = f'{image}{title}'\n",
    "        views = 5\n",
    "        add = pd.DataFrame([name, views]columns = [\"name\",\"views\"])\n",
    "        A = pd.concat([A,add],axis=0)\n",
    "#st.write(views)\n",
    "st.table(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_url = \"https://youtube.googleapis.com/youtube/v3/search\"\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "# params = {\n",
    "#     'publishedBefore':ledge,\n",
    "#     'part':'snippet',\n",
    "#     'order':'date',\n",
    "#     'q':'dog',\n",
    "#     'type':'video',\n",
    "#     'key': keys[0],\n",
    "#     'maxResults': 40}\n",
    "\n",
    "# # API response\n",
    "# search_response = requests.get(url=search_url, params=params)\n",
    "# if search_response.status_code != 200:\n",
    "#     print(search_response.status_code)\n",
    "\n",
    "\n",
    "# search_json = search_response.json()\n",
    "# search_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "that\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "was\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.12it/s]\n",
      "100%|██████████| 1/1 [00:32<00:00, 32.58s/it]\n"
     ]
    }
   ],
   "source": [
    "df_to_add = pd.DataFrame(columns=features)\n",
    "count = 0\n",
    "query_type = 'small'\n",
    "# hours = 24*90\n",
    "for _ in tqdm(range(int(1))):\n",
    "    search_query(query=None,max_results=2,start=start_time,end=end_time,ledge=ledge, hours=None, number_of_words=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_add.to_csv(f'{query_type}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_add.id.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_add.id.duplicated().sum()/len(df_to_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# %%\n",
    "df3 = pd.read_csv(\"lunch3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>country</th>\n",
       "      <th>channel_viewCount</th>\n",
       "      <th>channel_subscriberCount</th>\n",
       "      <th>channel_videoCount</th>\n",
       "      <th>title</th>\n",
       "      <th>published</th>\n",
       "      <th>views</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IkgedHOWgS8</td>\n",
       "      <td>UC8EzwgGkvr4h7jQIlOBRPrQ</td>\n",
       "      <td>JP</td>\n",
       "      <td>1874160</td>\n",
       "      <td>18400</td>\n",
       "      <td>60</td>\n",
       "      <td>【playlist】今日も一日お疲れ様。洋楽プレイリスト｜THE. music</td>\n",
       "      <td>2022-05-05T13:03:15Z</td>\n",
       "      <td>16846</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rRCUgDWq_5U</td>\n",
       "      <td>UC9zY_E8mcAo_Oq772LEZq8Q</td>\n",
       "      <td>JP</td>\n",
       "      <td>2566845299</td>\n",
       "      <td>7020000</td>\n",
       "      <td>474</td>\n",
       "      <td>ちゃんみな - ハレンチ / THE FIRST TAKE</td>\n",
       "      <td>2022-05-04T13:00:11Z</td>\n",
       "      <td>5847889</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QsuDpMrX6DQ</td>\n",
       "      <td>UCJZam2u1G0syq3kyqrCXrNw</td>\n",
       "      <td>US</td>\n",
       "      <td>4917608305</td>\n",
       "      <td>13600000</td>\n",
       "      <td>750</td>\n",
       "      <td>the dropper, but if I die the video ends…</td>\n",
       "      <td>2022-05-04T12:00:22Z</td>\n",
       "      <td>5469474</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-n5qcZwtMKk</td>\n",
       "      <td>UChX1KCEUgfy-sVNisjuyDkQ</td>\n",
       "      <td>TH</td>\n",
       "      <td>76290715</td>\n",
       "      <td>374000</td>\n",
       "      <td>1142</td>\n",
       "      <td>THE WORLD WE LIVE IN EP.2 – ไขรหัสว่า Content ...</td>\n",
       "      <td>2022-05-04T10:02:45Z</td>\n",
       "      <td>589</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g9Od0c5Mzw8</td>\n",
       "      <td>UCzYfz8uibvnB7Yc1LjePi4g</td>\n",
       "      <td>US</td>\n",
       "      <td>14572543681</td>\n",
       "      <td>14900000</td>\n",
       "      <td>4125</td>\n",
       "      <td>Becoming THE BAD GUYS In Minecraft!</td>\n",
       "      <td>2022-05-03T19:20:43Z</td>\n",
       "      <td>6168801</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6626</th>\n",
       "      <td>h1lpwd41Cwg</td>\n",
       "      <td>UCSf-NCzjwcnXErUBW_qeFvA</td>\n",
       "      <td>US</td>\n",
       "      <td>2181115984</td>\n",
       "      <td>4650000</td>\n",
       "      <td>513</td>\n",
       "      <td>Mismo Dios (Same God) | Letras Oficiales | Ele...</td>\n",
       "      <td>2022-10-07T04:00:27Z</td>\n",
       "      <td>168338</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6627</th>\n",
       "      <td>QLXZG5474_k</td>\n",
       "      <td>UCCCg8Fh5Avkt0lqD4wnAL6A</td>\n",
       "      <td>NO</td>\n",
       "      <td>51061189</td>\n",
       "      <td>170000</td>\n",
       "      <td>119</td>\n",
       "      <td>&amp;quot;We eat and train the same&amp;quot;</td>\n",
       "      <td>2022-10-06T16:35:21Z</td>\n",
       "      <td>739920</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6628</th>\n",
       "      <td>TLV91fTgjVY</td>\n",
       "      <td>UC-ikaAXJqrepGbTymwDURsg</td>\n",
       "      <td>US</td>\n",
       "      <td>24719812</td>\n",
       "      <td>102000</td>\n",
       "      <td>189</td>\n",
       "      <td>Do you have the same struggle?! (Tool link In ...</td>\n",
       "      <td>2022-10-06T01:12:51Z</td>\n",
       "      <td>21915</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6629</th>\n",
       "      <td>fHfJL0w5xBM</td>\n",
       "      <td>UCnBDxnkA628H1iTAsBcsWaA</td>\n",
       "      <td>US</td>\n",
       "      <td>198210</td>\n",
       "      <td>489</td>\n",
       "      <td>386</td>\n",
       "      <td>All Girls Are The same (prod.Beats For The Str...</td>\n",
       "      <td>2022-10-05T22:38:38Z</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6630</th>\n",
       "      <td>Kg68Fnb258Y</td>\n",
       "      <td>UC257b6MFXKs7JrxZGHOPH1w</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108499876</td>\n",
       "      <td>863000</td>\n",
       "      <td>261</td>\n",
       "      <td>Same spelling, different pronunciation 🇬🇧</td>\n",
       "      <td>2022-10-05T12:38:51Z</td>\n",
       "      <td>546344</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22629 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                channel_id country channel_viewCount  \\\n",
       "0     IkgedHOWgS8  UC8EzwgGkvr4h7jQIlOBRPrQ      JP           1874160   \n",
       "0     rRCUgDWq_5U  UC9zY_E8mcAo_Oq772LEZq8Q      JP        2566845299   \n",
       "0     QsuDpMrX6DQ  UCJZam2u1G0syq3kyqrCXrNw      US        4917608305   \n",
       "0     -n5qcZwtMKk  UChX1KCEUgfy-sVNisjuyDkQ      TH          76290715   \n",
       "0     g9Od0c5Mzw8  UCzYfz8uibvnB7Yc1LjePi4g      US       14572543681   \n",
       "...           ...                       ...     ...               ...   \n",
       "6626  h1lpwd41Cwg  UCSf-NCzjwcnXErUBW_qeFvA      US        2181115984   \n",
       "6627  QLXZG5474_k  UCCCg8Fh5Avkt0lqD4wnAL6A      NO          51061189   \n",
       "6628  TLV91fTgjVY  UC-ikaAXJqrepGbTymwDURsg      US          24719812   \n",
       "6629  fHfJL0w5xBM  UCnBDxnkA628H1iTAsBcsWaA      US            198210   \n",
       "6630  Kg68Fnb258Y  UC257b6MFXKs7JrxZGHOPH1w     NaN         108499876   \n",
       "\n",
       "     channel_subscriberCount channel_videoCount  \\\n",
       "0                      18400                 60   \n",
       "0                    7020000                474   \n",
       "0                   13600000                750   \n",
       "0                     374000               1142   \n",
       "0                   14900000               4125   \n",
       "...                      ...                ...   \n",
       "6626                 4650000                513   \n",
       "6627                  170000                119   \n",
       "6628                  102000                189   \n",
       "6629                     489                386   \n",
       "6630                  863000                261   \n",
       "\n",
       "                                                  title             published  \\\n",
       "0               【playlist】今日も一日お疲れ様。洋楽プレイリスト｜THE. music  2022-05-05T13:03:15Z   \n",
       "0                         ちゃんみな - ハレンチ / THE FIRST TAKE  2022-05-04T13:00:11Z   \n",
       "0             the dropper, but if I die the video ends…  2022-05-04T12:00:22Z   \n",
       "0     THE WORLD WE LIVE IN EP.2 – ไขรหัสว่า Content ...  2022-05-04T10:02:45Z   \n",
       "0                   Becoming THE BAD GUYS In Minecraft!  2022-05-03T19:20:43Z   \n",
       "...                                                 ...                   ...   \n",
       "6626  Mismo Dios (Same God) | Letras Oficiales | Ele...  2022-10-07T04:00:27Z   \n",
       "6627              &quot;We eat and train the same&quot;  2022-10-06T16:35:21Z   \n",
       "6628  Do you have the same struggle?! (Tool link In ...  2022-10-06T01:12:51Z   \n",
       "6629  All Girls Are The same (prod.Beats For The Str...  2022-10-05T22:38:38Z   \n",
       "6630          Same spelling, different pronunciation 🇬🇧  2022-10-05T12:38:51Z   \n",
       "\n",
       "        views  Unnamed: 0  \n",
       "0       16846         NaN  \n",
       "0     5847889         NaN  \n",
       "0     5469474         NaN  \n",
       "0         589         NaN  \n",
       "0     6168801         NaN  \n",
       "...       ...         ...  \n",
       "6626   168338         0.0  \n",
       "6627   739920         0.0  \n",
       "6628    21915         0.0  \n",
       "6629       28         0.0  \n",
       "6630   546344         0.0  \n",
       "\n",
       "[22629 rows x 10 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.concat([df_to_add,df3],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2847"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.id.duplicated().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.to_csv(f'big_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "\n",
    "def download_blob_into_memory(bucket_name, blob_name):\n",
    "    \"\"\"Downloads a blob into memory.\"\"\"\n",
    "    # The ID of your GCS bucket\n",
    "    # bucket_name = \"your-bucket-name\"\n",
    "\n",
    "    # The ID of your GCS object\n",
    "    # blob_name = \"storage-object-name\"\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "\n",
    "    # Construct a client side representation of a blob.\n",
    "    # Note `Bucket.blob` differs from `Bucket.get_blob` as it doesn't retrieve\n",
    "    # any content from Google Cloud Storage. As we don't need additional data,\n",
    "    # using `Bucket.blob` is preferred here.\n",
    "    blob = bucket.blob(blob_name)\n",
    "    contents = blob.download_as_string()\n",
    "\n",
    "    return plt.imread(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "embedded null byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m download_blob_into_memory(bucket_name, \u001b[39m'\u001b[39;49m\u001b[39mlunch4/05zSNupPJGE_7639\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn [42], line 23\u001b[0m, in \u001b[0;36mdownload_blob_into_memory\u001b[0;34m(bucket_name, blob_name)\u001b[0m\n\u001b[1;32m     20\u001b[0m blob \u001b[39m=\u001b[39m bucket\u001b[39m.\u001b[39mblob(blob_name)\n\u001b[1;32m     21\u001b[0m contents \u001b[39m=\u001b[39m blob\u001b[39m.\u001b[39mdownload_as_string()\n\u001b[0;32m---> 23\u001b[0m \u001b[39mreturn\u001b[39;00m plt\u001b[39m.\u001b[39;49mimread(contents)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/youtube_optimizer/lib/python3.10/site-packages/matplotlib/pyplot.py:2123\u001b[0m, in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   2121\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(matplotlib\u001b[39m.\u001b[39mimage\u001b[39m.\u001b[39mimread)\n\u001b[1;32m   2122\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mimread\u001b[39m(fname, \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m-> 2123\u001b[0m     \u001b[39mreturn\u001b[39;00m matplotlib\u001b[39m.\u001b[39;49mimage\u001b[39m.\u001b[39;49mimread(fname, \u001b[39mformat\u001b[39;49m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/youtube_optimizer/lib/python3.10/site-packages/matplotlib/image.py:1541\u001b[0m, in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   1534\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fname, \u001b[39mstr\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(parse\u001b[39m.\u001b[39murlparse(fname)\u001b[39m.\u001b[39mscheme) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1535\u001b[0m     \u001b[39m# Pillow doesn't handle URLs directly.\u001b[39;00m\n\u001b[1;32m   1536\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1537\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease open the URL for reading and pass the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1538\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mresult to Pillow, e.g. with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1539\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m``np.array(PIL.Image.open(urllib.request.urlopen(url)))``.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1540\u001b[0m         )\n\u001b[0;32m-> 1541\u001b[0m \u001b[39mwith\u001b[39;00m img_open(fname) \u001b[39mas\u001b[39;00m image:\n\u001b[1;32m   1542\u001b[0m     \u001b[39mreturn\u001b[39;00m (_pil_png_to_float_array(image)\n\u001b[1;32m   1543\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(image, PIL\u001b[39m.\u001b[39mPngImagePlugin\u001b[39m.\u001b[39mPngImageFile) \u001b[39melse\u001b[39;00m\n\u001b[1;32m   1544\u001b[0m             pil_to_array(image))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/youtube_optimizer/lib/python3.10/site-packages/PIL/ImageFile.py:104\u001b[0m, in \u001b[0;36mImageFile.__init__\u001b[0;34m(self, fp, filename)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecodermaxblock \u001b[39m=\u001b[39m MAXBLOCK\n\u001b[1;32m    102\u001b[0m \u001b[39mif\u001b[39;00m is_path(fp):\n\u001b[1;32m    103\u001b[0m     \u001b[39m# filename\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(fp, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    105\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilename \u001b[39m=\u001b[39m fp\n\u001b[1;32m    106\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exclusive_fp \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: embedded null byte"
     ]
    }
   ],
   "source": [
    "download_blob_into_memory(bucket_name, 'lunch4/05zSNupPJGE_7639')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# %%\n",
    "df = pd.read_csv(\"../../raw_data/df_merge.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64127"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit ('lewagon')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "796d12d58fed328bdf981f0b0501490a5479cc68e82a5c6b494e7225e4597e6f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
